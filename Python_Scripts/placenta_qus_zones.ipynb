{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acm4005\\AppData\\Local\\Temp\\ipykernel_5548\\2693331444.py:51: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  in_data[['ID','Day','Frame']] = in_data['ID'].str.split('_',2,expand=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "# statsmodels and sklearn are currently not used. Both packages can be omitted for now, but sklearn will\n",
    "# very likely be used in the future\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Folder containing the data file\n",
    "data_dir = r'C:\\Users\\acm4005\\Box\\WCM_Tulane_Shared_Folder\\Preeclampsia Model' # For UITC 2023 talk\n",
    "\n",
    "# Name of the file containing the QUS results\n",
    "#data_fid = r'2023-03-07_GD14-18.csv'\n",
    "data_fid = r'2023-07-28_segments.csv'\n",
    "\n",
    "# Define an array of the QUS parameter names. This will be useful later\n",
    "qus_params = ['ESD','EAC','MBF','SS','I0','Naka Omega','Naka m','HK k','HK alpha','Burr b','Burr lambda']\n",
    "\n",
    "# Move to the data folder and read the .csv into a DataFrame\n",
    "os.chdir(data_dir)\n",
    "in_data = pd.read_csv(data_fid)\n",
    "\n",
    "# Rename the columns using abbreviations for the parameter names\n",
    "new_names = {'HK Structure Param':'HK k','HK Scatterer Clustering Param':'HK alpha','Nak Shape Param':'Naka m','Nak Scale Factor':'Naka Omega', \n",
    "             'Spectral Slope':'SS','Intercept':'I0','Midband Fit':'MBF','Effective Scatterer Size':'ESD','Acoustic Concentration':'EAC',\n",
    "             'Burr_b':'Burr b','Burr_lambda':'Burr lambda'}\n",
    "in_data.rename(new_names,axis=1,inplace=True)\n",
    "\n",
    "# Convert ESD from m to um\n",
    "in_data['ESD'] *= 1e6\n",
    "\n",
    "# Log compress the Nakagami Omega and HK alpha parameters\n",
    "in_data['Naka Omega'] = np.log10(in_data['Naka Omega'])\n",
    "in_data['HK alpha'] = np.log10(in_data['HK alpha'])\n",
    "\n",
    "# As a precaution, remove any rows that contain a NaN in any column\n",
    "in_data.dropna(axis=0,inplace=True)\n",
    "\n",
    "in_data_copy = in_data.copy()\n",
    "\n",
    "# Based on the ID string, split into new columns with ID, Day, and Frame #\n",
    "in_data[['ID','Day','Frame']] = in_data['ID'].str.split('_',2,expand=True)\n",
    "\n",
    "# Convert Day column into integer data type (instead of string)\n",
    "in_data['Day'] = in_data['Day'].astype(int)\n",
    "\n",
    "# # Keep only the first 5 characters from the ID - the last specifies placenta (not animal) and is not needed at this time\n",
    "# # This will make it easier to separate the control and treat groups\n",
    "# in_data['ID'] = in_data['ID'].str[:5]\n",
    "\n",
    "# Remove any rows where the ESD is zero \n",
    "# This means QUS estimation failed\n",
    "remove_idx = (in_data['ESD'] <= 0)\n",
    "in_data.drop(in_data.loc[remove_idx].index,inplace=True)\n",
    "\n",
    "sum_data = in_data.groupby(['ID','Day'],as_index=False).count()\n",
    "\n",
    "#Specify placentas which do not meet the criteria for inclusion in this study\n",
    "#drop_placentas = {'RTG341_18_1','RTG344_18_1','RTG345_18_1','RTG361_18_1','RTG362_18_1','RTG363_18_1','RTG364_18_1','RTG371_18_1','RTG372_18_1','RTG375_18_1','RTG435_18_1','RTG441_18_1','RTG442_18_1','RTG445_18_1','RTG461_18_1','RTG462_18_1','RTG463_18_1','RTG465_18_1'}\n",
    "\n",
    "#for drop_p in drop_placentas:\n",
    "#    in_data_copy.drop(in_data_copy.loc[in_data_copy['ID'] == drop_p].index,inplace=True)\n",
    "\n",
    "\n",
    "# Rename the Group IDs to 'Control' and 'RUPP'\n",
    "in_data.loc[in_data['ID'].str[:5] == 'RTG11','Group'] = 'Control'\n",
    "in_data.loc[in_data['ID'].str[:5] == 'RTG36','Group'] = 'Control'\n",
    "in_data.loc[in_data['ID'].str[:5] == 'RTG37','Group'] = 'Control'\n",
    "in_data.loc[in_data['ID'].str[:5] == 'RTG43','Group'] = 'Control'\n",
    "in_data.loc[in_data['ID'].str[:5] == 'RTG34','Group'] = 'RUPP'\n",
    "in_data.loc[in_data['ID'].str[:5] == 'RTG44','Group'] = 'RUPP'\n",
    "in_data.loc[in_data['ID'].str[:5] == 'RTG46','Group'] = 'RUPP'\n",
    "\n",
    "#Generate string to save file\n",
    "in_data_18 = in_data[in_data['Day']==18]\n",
    "in_data_18.drop(columns = ['Day','Frame'],inplace=True)\n",
    "#in_data_18 = in_data_18.groupby(['ID'],as_index=False)\n",
    "save_csv = data_dir + r'\\day_18_data_' + data_fid[:-4] + r'.csv'\n",
    "\n",
    "#with pd.ExcelWriter(save_xls) as writer:\n",
    "#     in_data_18.to_excel(writer)\n",
    "\n",
    "in_data_18.to_csv(save_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
